{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "google-colab-setup-PySpark.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjKnwTnUo9tZ"
      },
      "source": [
        "# Data Processing using Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOEQDmmhphD2"
      },
      "source": [
        "#configuraciÃ³n en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKQ3ax7dtASF"
      },
      "source": [
        "#instalar java y spark\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxw3GWC5uQ_k"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X81wyQ97vFEm"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9iVsm74o9ta"
      },
      "source": [
        "# verificar que tenga previamente el paquete 'pyspark' instalado\n",
        "!pip install pyspark\n",
        "# en el cluster EMR no hay necesidad de instalar este paquete, ya viene con AWS EMR / Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GlJg-Ljo9tn"
      },
      "source": [
        "# Load csv Dataset \n",
        "df=spark.read.csv('sample_data/california_housing_test.csv',inferSchema=True,header=True)\n",
        "# desde S3\n",
        "# df=spark.read.csv('s3://bucke_name/datasets/sample_data.csv',inferSchema=True,header=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wwDyGy1o9tq"
      },
      "source": [
        "#columns of dataframe\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTuLwMcfo9tu"
      },
      "source": [
        "#check number of columns\n",
        "len(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ7X6U9No9tx"
      },
      "source": [
        "#number of records in dataframe\n",
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaorHkvko9t0"
      },
      "source": [
        "#shape of dataset\n",
        "print((df.count(),len(df.columns)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXRe9_Ofo9t3"
      },
      "source": [
        "#printSchema\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQJD8sYuo9t6"
      },
      "source": [
        "#fisrt few rows of dataframe\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJM5YbF4fabP"
      },
      "source": [
        "write_uri='gdrive/My Drive/github/salida_csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_0DOIw2fpXo"
      },
      "source": [
        "df.coalesce(1).write.format(\"csv\").option(\"header\",\"true\").save(write_uri)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}